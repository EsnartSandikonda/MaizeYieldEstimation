{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4 .tif files in 'Munda1' folder: D:\\Yield\\LR\\LandsatData\\Munda1\n",
            "Found 4 .tif files in 'Munda2' folder: D:\\Yield\\LR\\LandsatData\\Munda2\n",
            "Found 4 .tif files in 'Munda3' folder: D:\\Yield\\LR\\LandsatData\\Munda3\n",
            "Found 4 .tif files in 'Munda4' folder: D:\\Yield\\LR\\LandsatData\\Munda4\n",
            "Found 4 .tif files in 'Munda5' folder: D:\\Yield\\LR\\LandsatData\\Munda5\n",
            "Found 4 .tif files in 'Munda6' folder: D:\\Yield\\LR\\LandsatData\\Munda6\n",
            "Found 4 .tif files in 'Munda7' folder: D:\\Yield\\LR\\LandsatData\\Munda7\n",
            "Raw per-image features:\n",
            "  polygon       date                                 filename  mean_NDVI  \\\n",
            "0  Munda1        NaT                    20250210_20250215.tif   0.069857   \n",
            "1  Munda1        NaT                                   M1.tif   0.096473   \n",
            "2  Munda1 2024-11-13  M525-058polygon20241106_20241113_02.tif   0.022826   \n",
            "3  Munda1        NaT     M525-058polygon20241224_20241228.tif   0.021880   \n",
            "4  Munda2        NaT                    20250210_20250215.tif   0.049058   \n",
            "\n",
            "   mean_GNDVI  mean_SAVI  mean_Red  mean_Green   mean_NIR  \n",
            "0    0.071177   0.099755  2532.375   2503.5000  4497.1250  \n",
            "1    0.088087   0.137761  2134.000   2306.3750  4816.2500  \n",
            "2    0.040924   0.032595  3234.500   2791.6250  3884.5000  \n",
            "3    0.042063   0.031244  3496.625   2967.0000  4167.3750  \n",
            "4    0.050969   0.070054  2032.625   1988.3125  3474.1875  \n"
          ]
        }
      ],
      "source": [
        "# Base folder containing polygon folders\n",
        "base_folder = r\"D:\\Yield\\LR\\LandsatData\"\n",
        "\n",
        "# Polygon folders to process\n",
        "polygon_folders = ['Munda1', 'Munda2', 'Munda3', 'Munda4', 'Munda5', 'Munda6', 'Munda7']\n",
        "\n",
        "# Store results\n",
        "records = []\n",
        "\n",
        "for poly in polygon_folders:\n",
        "    folder_path = os.path.join(base_folder, poly)\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Warning: Folder not found for polygon '{poly}': {folder_path}\")\n",
        "        continue # Skip to the next polygon if folder does not exist\n",
        "\n",
        "    files = [f for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
        "    files.sort()\n",
        "\n",
        "    if not files:\n",
        "        print(f\"Warning: No .tif files found in folder for polygon '{poly}': {folder_path}\")\n",
        "        continue # Skip to the next polygon\n",
        "    else:\n",
        "        print(f\"Found {len(files)} .tif files in '{poly}' folder: {folder_path}\")\n",
        "\n",
        "    for file in files:\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "\n",
        "        with rasterio.open(file_path) as src:\n",
        "            red = src.read(4).astype('float32')\n",
        "            green = src.read(3).astype('float32')\n",
        "            nir = src.read(5).astype('float32')\n",
        "\n",
        "        # Vegetation Indices\n",
        "        ndvi = (nir - red) / (nir + red + 1e-10)\n",
        "        gndvi = (nir - green) / (nir + green + 1e-10)\n",
        "        savi = ((nir - red) / (nir + red + 0.428)) * 1.428  # L=0.428\n",
        "\n",
        "        # Mask invalid VI values\n",
        "        ndvi = np.where((ndvi >= -1) & (ndvi <= 1), ndvi, np.nan)\n",
        "        gndvi = np.where((gndvi >= -1) & (gndvi <= 1), gndvi, np.nan)\n",
        "        savi = np.where((savi >= -1) & (savi <= 1), savi, np.nan)\n",
        "\n",
        "        # Calculate VI means\n",
        "        mean_ndvi = np.nanmean(ndvi)\n",
        "        mean_gndvi = np.nanmean(gndvi)\n",
        "        mean_savi = np.nanmean(savi)\n",
        "\n",
        "        # Calculate mean reflectance of raw bands ===\n",
        "        mean_red = np.nanmean(red)\n",
        "        mean_green = np.nanmean(green)\n",
        "        mean_nir = np.nanmean(nir)\n",
        "\n",
        "        # Extract date\n",
        "        try:\n",
        "            date_str = file.split('_')[1]\n",
        "            date = datetime.strptime(date_str, \"%Y%m%d\")\n",
        "        except Exception:\n",
        "            date = None \n",
        "\n",
        "        # Append results\n",
        "        records.append({\n",
        "            'polygon': poly,\n",
        "            'date': date,\n",
        "            'filename': file,\n",
        "            'mean_NDVI': mean_ndvi,\n",
        "            'mean_GNDVI': mean_gndvi,\n",
        "            'mean_SAVI': mean_savi,\n",
        "            'mean_Red': mean_red,\n",
        "            'mean_Green': mean_green,\n",
        "            'mean_NIR': mean_nir\n",
        "        })\n",
        "\n",
        "# Create DataFrame\n",
        "df_indices = pd.DataFrame(records)\n",
        "print(\"Raw per-image features:\")\n",
        "print(df_indices.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged vegetation index + area data:\n",
            "  polygon       date                                 filename  mean_NDVI  \\\n",
            "0  Munda1        NaT                    20250210_20250215.tif   0.069857   \n",
            "1  Munda1        NaT                                   M1.tif   0.096473   \n",
            "2  Munda1 2024-11-13  M525-058polygon20241106_20241113_02.tif   0.022826   \n",
            "3  Munda1        NaT     M525-058polygon20241224_20241228.tif   0.021880   \n",
            "4  Munda2        NaT                    20250210_20250215.tif   0.049058   \n",
            "\n",
            "   mean_GNDVI  mean_SAVI  mean_Red  mean_Green   mean_NIR   area_ha  \n",
            "0    0.071177   0.099755  2532.375   2503.5000  4497.1250  0.101974  \n",
            "1    0.088087   0.137761  2134.000   2306.3750  4816.2500  0.101974  \n",
            "2    0.040924   0.032595  3234.500   2791.6250  3884.5000  0.101974  \n",
            "3    0.042063   0.031244  3496.625   2967.0000  4167.3750  0.101974  \n",
            "4    0.050969   0.070054  2032.625   1988.3125  3474.1875  0.339510  \n"
          ]
        }
      ],
      "source": [
        "# Load area data\n",
        "df_area = pd.read_csv(\"polygon_areas.csv\")\n",
        "\n",
        "# Merge area with vegetation index data\n",
        "df_indices = pd.merge(df_indices, df_area, on='polygon', how='left')\n",
        "\n",
        "# Check for any polygons without area info\n",
        "missing_area = df_indices[df_indices['area_ha'].isna()]\n",
        "if not missing_area.empty:\n",
        "    print(\"Warning: Some polygons are missing area values:\")\n",
        "    print(missing_area['polygon'].unique())\n",
        "\n",
        "# Show result\n",
        "print(\"Merged vegetation index + area data:\")\n",
        "print(df_indices.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available columns: ['polygon', 'date', 'filename', 'mean_NDVI', 'mean_GNDVI', 'mean_SAVI', 'mean_Red', 'mean_Green', 'mean_NIR', 'area_ha', 'yield_tons']\n",
            "Per-image data ready for modeling:\n",
            "  polygon       date                                 filename  mean_NDVI  \\\n",
            "0  Munda1        NaT                    20250210_20250215.tif   0.069857   \n",
            "1  Munda1        NaT                                   M1.tif   0.096473   \n",
            "2  Munda1 2024-11-13  M525-058polygon20241106_20241113_02.tif   0.022826   \n",
            "3  Munda1        NaT     M525-058polygon20241224_20241228.tif   0.021880   \n",
            "4  Munda2        NaT                    20250210_20250215.tif   0.049058   \n",
            "\n",
            "   mean_GNDVI  mean_SAVI  mean_Red  mean_Green   mean_NIR   area_ha  \\\n",
            "0    0.071177   0.099755  2532.375   2503.5000  4497.1250  0.101974   \n",
            "1    0.088087   0.137761  2134.000   2306.3750  4816.2500  0.101974   \n",
            "2    0.040924   0.032595  3234.500   2791.6250  3884.5000  0.101974   \n",
            "3    0.042063   0.031244  3496.625   2967.0000  4167.3750  0.101974   \n",
            "4    0.050969   0.070054  2032.625   1988.3125  3474.1875  0.339510   \n",
            "\n",
            "   yield_tons  \n",
            "0         0.9  \n",
            "1         0.9  \n",
            "2         0.9  \n",
            "3         0.9  \n",
            "4         1.3  \n"
          ]
        }
      ],
      "source": [
        "df_yield = pd.read_csv(\"yield_tons.csv\")\n",
        "\n",
        "# Merge with yield data\n",
        "df = pd.merge(df_indices, df_yield, on='polygon', how='inner')\n",
        "\n",
        "# Check which columns exist\n",
        "print(\"Available columns:\", df.columns.tolist())\n",
        "\n",
        "# Drop rows with missing data including band means\n",
        "df = df.dropna(subset=[\n",
        "    'mean_NDVI', 'mean_GNDVI', 'mean_SAVI', \n",
        "    'mean_Red', 'mean_Green', 'mean_NIR', \n",
        "    'area_ha', 'yield_tons'\n",
        "])\n",
        "\n",
        "# Show preview\n",
        "print(\"Per-image data ready for modeling:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image-level training dataset:\n",
            "  polygon  mean_NDVI  mean_GNDVI  mean_SAVI  mean_Red  mean_Green   mean_NIR  \\\n",
            "0  Munda1   0.069857    0.071177   0.099755  2532.375   2503.5000  4497.1250   \n",
            "1  Munda1   0.096473    0.088087   0.137761  2134.000   2306.3750  4816.2500   \n",
            "2  Munda1   0.022826    0.040924   0.032595  3234.500   2791.6250  3884.5000   \n",
            "3  Munda1   0.021880    0.042063   0.031244  3496.625   2967.0000  4167.3750   \n",
            "4  Munda2   0.049058    0.050969   0.070054  2032.625   1988.3125  3474.1875   \n",
            "\n",
            "    area_ha  yield_tons                                 filename  \n",
            "0  0.101974         0.9                    20250210_20250215.tif  \n",
            "1  0.101974         0.9                                   M1.tif  \n",
            "2  0.101974         0.9  M525-058polygon20241106_20241113_02.tif  \n",
            "3  0.101974         0.9     M525-058polygon20241224_20241228.tif  \n",
            "4  0.339510         1.3                    20250210_20250215.tif  \n"
          ]
        }
      ],
      "source": [
        "# Select only the columns needed for training\n",
        "df_summary = df[[\n",
        "    'polygon',\n",
        "    'mean_NDVI',\n",
        "    'mean_GNDVI',\n",
        "    'mean_SAVI',\n",
        "    'mean_Red',\n",
        "    'mean_Green',\n",
        "    'mean_NIR',\n",
        "    'area_ha',\n",
        "    'yield_tons',\n",
        "    'filename'\n",
        "]]\n",
        "\n",
        "# Drop rows with missing values (optional clean-up)\n",
        "df_summary = df_summary.dropna()\n",
        "\n",
        "# Show the final table\n",
        "print(\"Image-level training dataset:\")\n",
        "print(df_summary.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image-level Model Performance:\n",
            "R² Score: 0.2331\n",
            "RMSE (tons/ha): 0.4020\n",
            "MAE (tons/ha): 0.3258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Define features to use for training\n",
        "features = [\n",
        "    'mean_NDVI',\n",
        "    'mean_GNDVI',\n",
        "    'mean_SAVI',\n",
        "    'mean_Red',\n",
        "    'mean_Green',\n",
        "    'mean_NIR'\n",
        "]\n",
        "\n",
        "# Drop any rows with missing values in these features (safety check)\n",
        "df_summary = df_summary.dropna(subset=features + ['yield_tons'])\n",
        "\n",
        "# Define input (X) and output (y)\n",
        "X = df_summary[features]\n",
        "y = df_summary['yield_tons']  # Already in tons/ha\n",
        "\n",
        "# Train linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict on training data\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Evaluate model\n",
        "r2 = r2_score(y, y_pred)\n",
        "rmse = mean_squared_error(y, y_pred, squared=False)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "\n",
        "# Print performance\n",
        "print(\"Image-level Model Performance:\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "print(f\"RMSE (tons/ha): {rmse:.4f}\")\n",
        "print(f\"MAE (tons/ha): {mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average predicted yield per hectare for Munda6: 1.961 tons/ha\n"
          ]
        }
      ],
      "source": [
        "# Filter only test field from the df_indices DataFrame,\n",
        "df_munda6 = df_indices[df_indices['polygon'] == 'Munda6'].copy()\n",
        "\n",
        "# Check if test field data is actually present for prediction\n",
        "if df_munda6.empty:\n",
        "    print(\"Error: No Munda6 data found in df_indices for prediction. Ensure it loaded correctly in earlier steps.\")\n",
        "else:\n",
        "    # Predict yield per hectare for each test field image\n",
        "    # Only pass the 'features' columns to the model for prediction\n",
        "    df_munda6['predicted_yield_per_ha'] = model.predict(df_munda6[features])\n",
        "\n",
        "    # Calculate average predicted yield per hectare across all Munda6 images\n",
        "    avg_predicted_yield_per_ha = df_munda6['predicted_yield_per_ha'].mean()\n",
        "\n",
        "    print(f\"\\nAverage predicted yield per hectare for Munda6: {avg_predicted_yield_per_ha:.3f} tons/ha\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a3bd1f7527235d395ee2c430f9d8a2e674cce37f5b8953fb2e12628b1780f35"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
