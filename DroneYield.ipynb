{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d3530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae4f6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted vegetation indices and features from drone imagery (no masking, no standard deviations):\n",
      "  polygon  date    filename   mean_ExG  mean_GLI  mean_VARI   mean_TGI  \\\n",
      "0  Munda1  None  Munda1.tif  29.988546  0.084960   0.005946  18.162916   \n",
      "1  Munda2  None  Munda2.tif  16.802973  0.040981  -0.038630  11.502631   \n",
      "2  Munda3  None  Munda3.tif  29.551044  0.077395  -0.044689  19.322803   \n",
      "3  Munda4  None  Munda4.tif  21.299973  0.058161  -0.026116  13.652133   \n",
      "4  Munda5  None  Munda5.tif  29.342831  0.077635   0.011176  17.655802   \n",
      "\n",
      "   mean_CIVE   mean_Red  mean_Green  mean_Blue  \n",
      "0  18.727116  72.174706   72.766083  43.368896  \n",
      "1  18.757044  64.890701   59.196167  36.698555  \n",
      "2  18.732512  88.398834   82.504814  47.059834  \n",
      "3  18.746469  58.684658   55.688457  31.392330  \n",
      "4  18.732330  68.685951   69.791962  41.555145  \n",
      "\n",
      "Unique polygons found in drone data:\n",
      "['Munda1' 'Munda2' 'Munda3' 'Munda4' 'Munda5' 'Munda6' 'Munda7']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Base folder containing all drone image files\n",
    "image_folder = r\"D:\\Yield\\Estimation\\DroneData\"\n",
    "records = []\n",
    "\n",
    "# List all .tif files within the specified drone image folder\n",
    "files = [f for f in os.listdir(image_folder) if f.endswith('.tif')]\n",
    "files.sort()\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(image_folder, file)\n",
    "\n",
    "    try:\n",
    "        with rasterio.open(file_path) as src:\n",
    "            red = src.read(1).astype('float32')\n",
    "            green = src.read(2).astype('float32')\n",
    "            blue = src.read(3).astype('float32')\n",
    "\n",
    "        # Calculate Vegetation Indices\n",
    "        exg = 2 * green - red - blue\n",
    "        gli = (2 * green - red - blue) / (2 * green + red + blue + 1e-10)\n",
    "        vari = (green - red) / (green + red - blue + 1e-10)\n",
    "        tgi = green - 0.39 * red - 0.61 * blue\n",
    "        sum_rgb = red + green + blue + 1e-10\n",
    "        r_norm = red / sum_rgb\n",
    "        g_norm = green / sum_rgb\n",
    "        b_norm = blue / sum_rgb\n",
    "        cive = 0.441 * r_norm - 0.881 * g_norm + 0.385 * b_norm + 18.78745\n",
    "\n",
    "        # Clean up potential infinite or NaN values\n",
    "        exg = np.where(np.isfinite(exg), exg, np.nan)\n",
    "        gli = np.where(np.isfinite(gli), gli, np.nan)\n",
    "        vari = np.where(np.isfinite(vari), vari, np.nan)\n",
    "        tgi = np.where(np.isfinite(tgi), tgi, np.nan)\n",
    "        cive = np.where(np.isfinite(cive), cive, np.nan)\n",
    "\n",
    "        # Calculate Mean Values (using UNMASKED data)\n",
    "        mean_exg = np.nanmean(exg)\n",
    "        mean_gli = np.nanmean(gli)\n",
    "        mean_vari = np.nanmean(vari)\n",
    "        mean_tgi = np.nanmean(tgi)\n",
    "        mean_cive = np.nanmean(cive)\n",
    "        mean_red = np.nanmean(red)\n",
    "        mean_green = np.nanmean(green)\n",
    "        mean_blue = np.nanmean(blue)\n",
    "\n",
    "        # Extract polygon name from filename\n",
    "        try:\n",
    "            polygon = file.split('.')[0]\n",
    "            date = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting polygon name from '{file}': {e}. Polygon set to None.\")\n",
    "            polygon = None\n",
    "            date = None\n",
    "\n",
    "        # Append extracted features and metadata to records list\n",
    "        records.append({\n",
    "            'polygon': polygon,\n",
    "            'date': date,\n",
    "            'filename': file,\n",
    "            'mean_ExG': mean_exg,\n",
    "            'mean_GLI': mean_gli,\n",
    "            'mean_VARI': mean_vari,\n",
    "            'mean_TGI': mean_tgi,\n",
    "            'mean_CIVE': mean_cive,\n",
    "            'mean_Red': mean_red,\n",
    "            'mean_Green': mean_green,\n",
    "            'mean_Blue': mean_blue,\n",
    "        })\n",
    "\n",
    "    except rasterio.errors.RasterioIOError as e:\n",
    "        print(f\"Error opening or reading raster file '{file_path}': {e}. Skipping this file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while processing '{file_path}': {e}. Skipping this file.\")\n",
    "\n",
    "# Create DataFrame from collected records\n",
    "df_indices = pd.DataFrame(records)\n",
    "\n",
    "print(\"✅ Extracted vegetation indices and features from drone imagery (no masking, no standard deviations):\")\n",
    "print(df_indices.head())\n",
    "print(\"\\nUnique polygons found in drone data:\")\n",
    "print(df_indices['polygon'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4aa69e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged drone vegetation index features with polygon area data:\n",
      "  polygon  date    filename   mean_ExG  mean_GLI  mean_VARI   mean_TGI  \\\n",
      "0  Munda1  None  Munda1.tif  29.988546  0.084960   0.005946  18.162916   \n",
      "1  Munda2  None  Munda2.tif  16.802973  0.040981  -0.038630  11.502631   \n",
      "2  Munda3  None  Munda3.tif  29.551044  0.077395  -0.044689  19.322803   \n",
      "3  Munda4  None  Munda4.tif  21.299973  0.058161  -0.026116  13.652133   \n",
      "4  Munda5  None  Munda5.tif  29.342831  0.077635   0.011176  17.655802   \n",
      "\n",
      "   mean_CIVE   mean_Red  mean_Green  mean_Blue   area_ha  \n",
      "0  18.727116  72.174706   72.766083  43.368896  0.101974  \n",
      "1  18.757044  64.890701   59.196167  36.698555  0.339510  \n",
      "2  18.732512  88.398834   82.504814  47.059834  0.308073  \n",
      "3  18.746469  58.684658   55.688457  31.392330  0.289367  \n",
      "4  18.732330  68.685951   69.791962  41.555145  0.185417  \n",
      "\n",
      "Available columns after merging with yield data:\n",
      "['polygon', 'date', 'filename', 'mean_ExG', 'mean_GLI', 'mean_VARI', 'mean_TGI', 'mean_CIVE', 'mean_Red', 'mean_Green', 'mean_Blue', 'area_ha', 'yield_tons']\n",
      "\n",
      "✅ Per-image data ready for modeling (drone data):\n",
      "  polygon  date    filename   mean_ExG  mean_GLI  mean_VARI   mean_TGI  \\\n",
      "0  Munda1  None  Munda1.tif  29.988546  0.084960   0.005946  18.162916   \n",
      "1  Munda2  None  Munda2.tif  16.802973  0.040981  -0.038630  11.502631   \n",
      "2  Munda3  None  Munda3.tif  29.551044  0.077395  -0.044689  19.322803   \n",
      "3  Munda4  None  Munda4.tif  21.299973  0.058161  -0.026116  13.652133   \n",
      "4  Munda5  None  Munda5.tif  29.342831  0.077635   0.011176  17.655802   \n",
      "\n",
      "   mean_CIVE   mean_Red  mean_Green  mean_Blue   area_ha  yield_tons  \n",
      "0  18.727116  72.174706   72.766083  43.368896  0.101974         0.9  \n",
      "1  18.757044  64.890701   59.196167  36.698555  0.339510         1.3  \n",
      "2  18.732512  88.398834   82.504814  47.059834  0.308073         1.4  \n",
      "3  18.746469  58.684658   55.688457  31.392330  0.289367         0.7  \n",
      "4  18.732330  68.685951   69.791962  41.555145  0.185417         1.1  \n",
      "\n",
      "Polygons included in the training dataset:\n",
      "['Munda1' 'Munda2' 'Munda3' 'Munda4' 'Munda5' 'Munda7']\n",
      "\n",
      "✅ Image-level training dataset (for drone data - df_summary):\n",
      "  polygon   mean_ExG  mean_GLI  mean_VARI   mean_TGI  mean_CIVE   mean_Red  \\\n",
      "0  Munda1  29.988546  0.084960   0.005946  18.162916  18.727116  72.174706   \n",
      "1  Munda2  16.802973  0.040981  -0.038630  11.502631  18.757044  64.890701   \n",
      "2  Munda3  29.551044  0.077395  -0.044689  19.322803  18.732512  88.398834   \n",
      "3  Munda4  21.299973  0.058161  -0.026116  13.652133  18.746469  58.684658   \n",
      "4  Munda5  29.342831  0.077635   0.011176  17.655802  18.732330  68.685951   \n",
      "\n",
      "   mean_Green  mean_Blue   area_ha  yield_tons    filename  \n",
      "0   72.766083  43.368896  0.101974         0.9  Munda1.tif  \n",
      "1   59.196167  36.698555  0.339510         1.3  Munda2.tif  \n",
      "2   82.504814  47.059834  0.308073         1.4  Munda3.tif  \n",
      "3   55.688457  31.392330  0.289367         0.7  Munda4.tif  \n",
      "4   69.791962  41.555145  0.185417         1.1  Munda5.tif  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Ensure pandas is imported if not already in the environment\n",
    "\n",
    "# --- Load and Merge Polygon Area Data ---\n",
    "df_area = pd.read_csv(\"polygon_areas.csv\")\n",
    "\n",
    "# Merge the area data (df_area) with your drone vegetation index features (df_indices).\n",
    "# 'how='left'' ensures all rows from df_indices are kept.\n",
    "df_indices = pd.merge(df_indices, df_area, on='polygon', how='left')\n",
    "\n",
    "# Check for any polygons missing area values after the merge.\n",
    "missing_area = df_indices[df_indices['area_ha'].isna()]\n",
    "if not missing_area.empty:\n",
    "    print(\"Warning: Some polygons in your drone dataset are missing area values:\")\n",
    "    print(missing_area['polygon'].unique())\n",
    "    print(\"Please ensure these polygons have entries in 'polygon_areas.csv'.\")\n",
    "\n",
    "print(\"✅ Merged drone vegetation index features with polygon area data:\")\n",
    "print(df_indices.head())\n",
    "\n",
    "\n",
    "# --- Load and Merge Yield Data ---\n",
    "df_yield = pd.read_csv(\"yield_tons.csv\")\n",
    "\n",
    "# Merge the drone features (df_indices, now including 'area_ha') with the yield data.\n",
    "df = pd.merge(df_indices, df_yield, on='polygon', how='inner')\n",
    "\n",
    "print(\"\\nAvailable columns after merging with yield data:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Drop rows with any missing data in specified columns.\n",
    "df = df.dropna(subset=[\n",
    "    'mean_ExG', 'mean_GLI', 'mean_VARI',\n",
    "    'mean_TGI', 'mean_CIVE',\n",
    "    'mean_Red', 'mean_Green', 'mean_Blue',\n",
    "    'area_ha', 'yield_tons'\n",
    "])\n",
    "\n",
    "print(\"\\n✅ Per-image data ready for modeling (drone data):\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nPolygons included in the training dataset:\")\n",
    "print(df['polygon'].unique())\n",
    "\n",
    "# --- Prepare df_summary for Cross-Validation ---\n",
    "# Select columns for df_summary.\n",
    "df_summary = df[[\n",
    "    'polygon',\n",
    "    'mean_ExG',\n",
    "    'mean_GLI',\n",
    "    'mean_VARI',\n",
    "    'mean_TGI',\n",
    "    'mean_CIVE',\n",
    "    'mean_Red',\n",
    "    'mean_Green',\n",
    "    'mean_Blue',\n",
    "    'area_ha',\n",
    "    'yield_tons',\n",
    "    'filename'\n",
    "]].copy()\n",
    "\n",
    "# Drop any rows with missing values in df_summary.\n",
    "df_summary = df_summary.dropna()\n",
    "\n",
    "print(\"\\n✅ Image-level training dataset (for drone data - df_summary):\")\n",
    "print(df_summary.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f441037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns after merging with yield data:\n",
      "['polygon', 'date', 'filename', 'mean_ExG', 'mean_GLI', 'mean_VARI', 'mean_TGI', 'mean_CIVE', 'mean_Red', 'mean_Green', 'mean_Blue', 'area_ha', 'yield_tons']\n",
      "\n",
      "✅ Per-image data ready for modeling (drone data - base for LOOCV):\n",
      "  polygon  date    filename   mean_ExG  mean_GLI  mean_VARI   mean_TGI  \\\n",
      "0  Munda1  None  Munda1.tif  29.988546  0.084960   0.005946  18.162916   \n",
      "1  Munda2  None  Munda2.tif  16.802973  0.040981  -0.038630  11.502631   \n",
      "2  Munda3  None  Munda3.tif  29.551044  0.077395  -0.044689  19.322803   \n",
      "3  Munda4  None  Munda4.tif  21.299973  0.058161  -0.026116  13.652133   \n",
      "4  Munda5  None  Munda5.tif  29.342831  0.077635   0.011176  17.655802   \n",
      "\n",
      "   mean_CIVE   mean_Red  mean_Green  mean_Blue   area_ha  yield_tons  \n",
      "0  18.727116  72.174706   72.766083  43.368896  0.101974         0.9  \n",
      "1  18.757044  64.890701   59.196167  36.698555  0.339510         1.3  \n",
      "2  18.732512  88.398834   82.504814  47.059834  0.308073         1.4  \n",
      "3  18.746469  58.684658   55.688457  31.392330  0.289367         0.7  \n",
      "4  18.732330  68.685951   69.791962  41.555145  0.185417         1.1  \n",
      "\n",
      "Polygons included in the base dataset for LOOCV:\n",
      "['Munda1' 'Munda2' 'Munda3' 'Munda4' 'Munda5' 'Munda7']\n"
     ]
    }
   ],
   "source": [
    "# Load yield data.\n",
    "df_yield = pd.read_csv(\"yield_tons.csv\")\n",
    "\n",
    "# Merge drone feature data with yield data.\n",
    "df = pd.merge(df_indices, df_yield, on='polygon', how='inner')\n",
    "\n",
    "# Check available columns after merging.\n",
    "print(\"Available columns after merging with yield data:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Define all features, including the new ones, for dropping rows with missing data.\n",
    "all_features_for_dropna = [\n",
    "    'mean_ExG', 'mean_GLI', 'mean_VARI',\n",
    "    'mean_TGI', 'mean_CIVE',\n",
    "    'mean_Red', 'mean_Green', 'mean_Blue',\n",
    "    'area_ha', 'yield_tons'\n",
    "]\n",
    "\n",
    "# Drop rows with any missing data in the specified columns.\n",
    "df = df.dropna(subset=all_features_for_dropna)\n",
    "\n",
    "print(\"\\n✅ Per-image data ready for modeling (drone data - base for LOOCV):\")\n",
    "print(df.head())\n",
    "print(\"\\nPolygons included in the base dataset for LOOCV:\")\n",
    "print(df['polygon'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8760562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Debugging df before df_summary creation ---\n",
      "Columns in df before creating df_summary: ['polygon', 'date', 'filename', 'mean_ExG', 'mean_GLI', 'mean_VARI', 'mean_TGI', 'mean_CIVE', 'mean_Red', 'mean_Green', 'mean_Blue', 'area_ha', 'yield_tons']\n",
      "--- Debugging df END ---\n",
      "\n",
      "\n",
      "✅ Image-level training dataset (for drone data - LOOCV base):\n",
      "  polygon   mean_ExG  mean_GLI  mean_VARI   mean_TGI  mean_CIVE   mean_Red  \\\n",
      "0  Munda1  29.988546  0.084960   0.005946  18.162916  18.727116  72.174706   \n",
      "1  Munda2  16.802973  0.040981  -0.038630  11.502631  18.757044  64.890701   \n",
      "2  Munda3  29.551044  0.077395  -0.044689  19.322803  18.732512  88.398834   \n",
      "3  Munda4  21.299973  0.058161  -0.026116  13.652133  18.746469  58.684658   \n",
      "4  Munda5  29.342831  0.077635   0.011176  17.655802  18.732330  68.685951   \n",
      "\n",
      "   mean_Green  mean_Blue   area_ha  yield_tons    filename  \n",
      "0   72.766083  43.368896  0.101974         0.9  Munda1.tif  \n",
      "1   59.196167  36.698555  0.339510         1.3  Munda2.tif  \n",
      "2   82.504814  47.059834  0.308073         1.4  Munda3.tif  \n",
      "3   55.688457  31.392330  0.289367         0.7  Munda4.tif  \n",
      "4   69.791962  41.555145  0.185417         1.1  Munda5.tif  \n",
      "\n",
      "Polygons in df_summary (all available for LOOCV):\n",
      "['Munda1' 'Munda2' 'Munda3' 'Munda4' 'Munda5' 'Munda7']\n"
     ]
    }
   ],
   "source": [
    "# --- DEBUGGING ADDITION START ---\n",
    "print(\"\\n--- Debugging df before df_summary creation ---\")\n",
    "print(f\"Columns in df before creating df_summary: {df.columns.tolist()}\")\n",
    "print(\"--- Debugging df END ---\\n\")\n",
    "# --- DEBUGGING ADDITION END ---\n",
    "\n",
    "# Select only the columns needed for training and testing in the LOOCV loop.\n",
    "# This ensures df_summary contains all the new features.\n",
    "df_summary = df[[\n",
    "    'polygon',\n",
    "    'mean_ExG',\n",
    "    'mean_GLI',\n",
    "    'mean_VARI',\n",
    "    'mean_TGI',\n",
    "    'mean_CIVE',\n",
    "    'mean_Red',\n",
    "    'mean_Green',\n",
    "    'mean_Blue',\n",
    "    'area_ha',\n",
    "    'yield_tons',\n",
    "    'filename'\n",
    "]].copy()\n",
    "\n",
    "# Drop any rows with missing values as a final clean-up step for the summary DataFrame.\n",
    "df_summary = df_summary.dropna()\n",
    "\n",
    "print(\"\\n✅ Image-level training dataset (for drone data - LOOCV base):\")\n",
    "print(df_summary.head())\n",
    "print(\"\\nPolygons in df_summary (all available for LOOCV):\")\n",
    "print(df_summary['polygon'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f933b476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Debugging df_summary before Custom Cross-Validation ---\n",
      "Shape of df_summary: (6, 12)\n",
      "Columns in df_summary: ['polygon', 'mean_ExG', 'mean_GLI', 'mean_VARI', 'mean_TGI', 'mean_CIVE', 'mean_Red', 'mean_Green', 'mean_Blue', 'area_ha', 'yield_tons', 'filename']\n",
      "Unique polygons in df_summary: ['Munda1', 'Munda2', 'Munda3', 'Munda4', 'Munda5', 'Munda7']\n",
      "--- Debugging df_summary END ---\n",
      "\n",
      "Starting Custom Cross-Validation: Training on 5 fields, Testing on 1 field.\n",
      "Total unique polygons available: 6\n",
      "Polygons in dataset: ['Munda1', 'Munda2', 'Munda3', 'Munda4', 'Munda5', 'Munda7']\n",
      "\n",
      "--- Fold 1: Testing on 'Munda1' ---\n",
      "  Training polygons for this fold: ['Munda2', 'Munda3', 'Munda4', 'Munda5', 'Munda7']\n",
      "  Unused polygons in this fold: []\n",
      "  Warning: y_test for 'Munda1' has no variance. Test R² will be NaN for this fold.\n",
      "  Training R²: 1.0000 | Training RMSE: 0.0000 | Training MAE: 0.0000\n",
      "  Test R²: nan | Test RMSE: 0.2948 | Test MAE: 0.2948\n",
      "\n",
      "--- Fold 2: Testing on 'Munda2' ---\n",
      "  Training polygons for this fold: ['Munda1', 'Munda3', 'Munda4', 'Munda5', 'Munda7']\n",
      "  Unused polygons in this fold: []\n",
      "  Warning: y_test for 'Munda2' has no variance. Test R² will be NaN for this fold.\n",
      "  Training R²: 1.0000 | Training RMSE: 0.0001 | Training MAE: 0.0001\n",
      "  Test R²: nan | Test RMSE: 8.3828 | Test MAE: 8.3828\n",
      "\n",
      "--- Fold 3: Testing on 'Munda3' ---\n",
      "  Training polygons for this fold: ['Munda1', 'Munda2', 'Munda4', 'Munda5', 'Munda7']\n",
      "  Unused polygons in this fold: []\n",
      "  Warning: y_test for 'Munda3' has no variance. Test R² will be NaN for this fold.\n",
      "  Training R²: 1.0000 | Training RMSE: 0.0000 | Training MAE: 0.0000\n",
      "  Test R²: nan | Test RMSE: 2.5250 | Test MAE: 2.5250\n",
      "\n",
      "--- Fold 4: Testing on 'Munda4' ---\n",
      "  Training polygons for this fold: ['Munda1', 'Munda2', 'Munda3', 'Munda5', 'Munda7']\n",
      "  Unused polygons in this fold: []\n",
      "  Warning: y_test for 'Munda4' has no variance. Test R² will be NaN for this fold.\n",
      "  Training R²: 1.0000 | Training RMSE: 0.0000 | Training MAE: 0.0000\n",
      "  Test R²: nan | Test RMSE: 2.2337 | Test MAE: 2.2337\n",
      "\n",
      "--- Fold 5: Testing on 'Munda5' ---\n",
      "  Training polygons for this fold: ['Munda1', 'Munda2', 'Munda3', 'Munda4', 'Munda7']\n",
      "  Unused polygons in this fold: []\n",
      "  Warning: y_test for 'Munda5' has no variance. Test R² will be NaN for this fold.\n",
      "  Training R²: 1.0000 | Training RMSE: 0.0000 | Training MAE: 0.0000\n",
      "  Test R²: nan | Test RMSE: 0.3008 | Test MAE: 0.3008\n",
      "\n",
      "--- Fold 6: Testing on 'Munda7' ---\n",
      "  Training polygons for this fold: ['Munda1', 'Munda2', 'Munda3', 'Munda4', 'Munda5']\n",
      "  Unused polygons in this fold: []\n",
      "  Warning: y_test for 'Munda7' has no variance. Test R² will be NaN for this fold.\n",
      "  Training R²: 1.0000 | Training RMSE: 0.0000 | Training MAE: 0.0000\n",
      "  Test R²: nan | Test RMSE: 77943.5397 | Test MAE: 77943.5397\n",
      "\n",
      "--- Average Model Performance (Custom Cross-Validation Results) ---\n",
      "Total number of folds completed: 6\n",
      "--- Test Set Averages ---\n",
      "Average Test R² Score: nan\n",
      "Average Test RMSE (tons/ha): 12992.8795\n",
      "Average Test MAE (tons/ha): 12992.8795\n",
      "\n",
      "--- Training Set Averages ---\n",
      "Average Training R² Score: 1.0000\n",
      "Average Training RMSE (tons/ha): 0.0000\n",
      "Average Training MAE (tons/ha): 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_12692\\1386023192.py:134: RuntimeWarning: Mean of empty slice\n",
      "  avg_test_r2 = np.nanmean(test_r2_scores)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# Define features for training and prediction.\n",
    "# These features now only include mean indices and raw bands, as per recent changes.\n",
    "features = [\n",
    "    'mean_ExG',\n",
    "    'mean_GLI',\n",
    "    'mean_VARI',\n",
    "    'mean_TGI',\n",
    "    'mean_CIVE',\n",
    "    'mean_Red',\n",
    "    'mean_Green',\n",
    "    'mean_Blue'\n",
    "]\n",
    "\n",
    "# Debugging information to check df_summary before cross-validation.\n",
    "print(\"\\n--- Debugging df_summary before Custom Cross-Validation ---\")\n",
    "print(f\"Shape of df_summary: {df_summary.shape}\")\n",
    "print(f\"Columns in df_summary: {df_summary.columns.tolist()}\")\n",
    "print(f\"Unique polygons in df_summary: {df_summary['polygon'].unique().tolist()}\")\n",
    "print(\"--- Debugging df_summary END ---\\n\")\n",
    "\n",
    "# Get all unique polygon identifiers from the df_summary DataFrame.\n",
    "unique_polygons = df_summary['polygon'].unique().tolist()\n",
    "num_total_polygons = len(unique_polygons)\n",
    "\n",
    "# Define the desired sizes for the training and test sets in each fold.\n",
    "train_set_size = 5\n",
    "test_set_size = 1\n",
    "\n",
    "# Initialize lists to store performance metrics for both test and training sets.\n",
    "test_r2_scores = []\n",
    "test_rmse_scores = []\n",
    "test_mae_scores = []\n",
    "\n",
    "train_r2_scores = []\n",
    "train_rmse_scores = []\n",
    "train_mae_scores = []\n",
    "\n",
    "print(f\"Starting Custom Cross-Validation: Training on {train_set_size} fields, Testing on {test_set_size} field.\")\n",
    "print(f\"Total unique polygons available: {num_total_polygons}\")\n",
    "print(f\"Polygons in dataset: {unique_polygons}\")\n",
    "\n",
    "fold_counter = 0\n",
    "\n",
    "# Outer loop: Iterate through each unique polygon, setting it as the test polygon for a set of folds.\n",
    "for test_polygon in unique_polygons:\n",
    "    # Create the test set DataFrame for the current test polygon.\n",
    "    df_test_fold = df_summary[df_summary['polygon'] == test_polygon].copy()\n",
    "\n",
    "    # Skip if the test set is empty.\n",
    "    if df_test_fold.empty:\n",
    "        print(f\"Warning: Test set is empty for '{test_polygon}'. Skipping folds with this test polygon.\")\n",
    "        continue\n",
    "\n",
    "    # Identify candidate polygons for the training set (all except the current test polygon).\n",
    "    candidate_train_polygons = [p for p in unique_polygons if p != test_polygon]\n",
    "\n",
    "    # Inner loop: Generate all combinations of 'train_set_size' polygons from candidates for training.\n",
    "    for train_subset_polygons in combinations(candidate_train_polygons, train_set_size):\n",
    "        fold_counter += 1\n",
    "        print(f\"\\n--- Fold {fold_counter}: Testing on '{test_polygon}' ---\")\n",
    "        print(f\"  Training polygons for this fold: {list(train_subset_polygons)}\")\n",
    "\n",
    "        # Identify and print polygons not used in this specific fold.\n",
    "        unused_polygons = [p for p in candidate_train_polygons if p not in train_subset_polygons]\n",
    "        print(f\"  Unused polygons in this fold: {unused_polygons}\")\n",
    "\n",
    "        # Create the training set DataFrame for the current fold.\n",
    "        df_train_fold = df_summary[df_summary['polygon'].isin(train_subset_polygons)].copy()\n",
    "\n",
    "        # Skip if the training set is empty.\n",
    "        if df_train_fold.empty:\n",
    "            print(f\"Warning: Training set is empty for fold {fold_counter}. Skipping this fold.\")\n",
    "            continue\n",
    "\n",
    "        # Define X (features) and y (target) for the training set.\n",
    "        X_train = df_train_fold[features]\n",
    "        y_train = df_train_fold['yield_tons']\n",
    "\n",
    "        # Define X (features) and y (target) for the test set.\n",
    "        X_test = df_test_fold[features]\n",
    "        y_test = df_test_fold['yield_tons']\n",
    "\n",
    "        # Initialize and train the linear regression model.\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calculate Training Set Performance.\n",
    "        y_pred_train = model.predict(X_train)\n",
    "\n",
    "        # Calculate R² for training, handling cases with no variance in y_train.\n",
    "        if len(y_train.unique()) > 1:\n",
    "            fold_train_r2 = r2_score(y_train, y_pred_train)\n",
    "        else:\n",
    "            fold_train_r2 = np.nan\n",
    "            print(f\"  Warning: y_train for fold {fold_counter} has no variance. Training R² will be NaN.\")\n",
    "\n",
    "        fold_train_rmse = root_mean_squared_error(y_train, y_pred_train)\n",
    "        fold_train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "        train_r2_scores.append(fold_train_r2)\n",
    "        train_rmse_scores.append(fold_train_rmse)\n",
    "        train_mae_scores.append(fold_train_mae)\n",
    "\n",
    "        # Calculate Test Set Performance.\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        # Calculate R² for testing, handling cases with no variance in y_test.\n",
    "        if len(y_test.unique()) > 1:\n",
    "            fold_test_r2 = r2_score(y_test, y_pred_test)\n",
    "        else:\n",
    "            fold_test_r2 = np.nan\n",
    "            print(f\"  Warning: y_test for '{test_polygon}' has no variance. Test R² will be NaN for this fold.\")\n",
    "\n",
    "        fold_test_rmse = root_mean_squared_error(y_test, y_pred_test)\n",
    "        fold_test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "        test_r2_scores.append(fold_test_r2)\n",
    "        test_rmse_scores.append(fold_test_rmse)\n",
    "        test_mae_scores.append(fold_test_mae)\n",
    "\n",
    "        # Print performance metrics for the current fold.\n",
    "        print(f\"  Training R²: {fold_train_r2:.4f} | Training RMSE: {fold_train_rmse:.4f} | Training MAE: {fold_train_mae:.4f}\")\n",
    "        print(f\"  Test R²: {fold_test_r2:.4f} | Test RMSE: {fold_test_rmse:.4f} | Test MAE: {fold_test_mae:.4f}\")\n",
    "\n",
    "\n",
    "# Calculate overall average performance metrics across all folds.\n",
    "# np.nanmean is used to correctly handle any NaN values.\n",
    "if test_r2_scores:\n",
    "    avg_test_r2 = np.nanmean(test_r2_scores)\n",
    "    avg_test_rmse = np.nanmean(test_rmse_scores)\n",
    "    avg_test_mae = np.nanmean(test_mae_scores)\n",
    "\n",
    "    avg_train_r2 = np.nanmean(train_r2_scores)\n",
    "    avg_train_rmse = np.nanmean(train_rmse_scores)\n",
    "    avg_train_mae = np.nanmean(train_mae_scores)\n",
    "\n",
    "    print(\"\\n--- Average Model Performance (Custom Cross-Validation Results) ---\")\n",
    "    print(f\"Total number of folds completed: {fold_counter}\")\n",
    "    print(\"--- Test Set Averages ---\")\n",
    "    print(f\"Average Test R² Score: {avg_test_r2:.4f}\")\n",
    "    print(f\"Average Test RMSE (tons/ha): {avg_test_rmse:.4f}\")\n",
    "    print(f\"Average Test MAE (tons/ha): {avg_test_mae:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Training Set Averages ---\")\n",
    "    print(f\"Average Training R² Score: {avg_train_r2:.4f}\")\n",
    "    print(f\"Average Training RMSE (tons/ha): {avg_train_rmse:.4f}\")\n",
    "    print(f\"Average Training MAE (tons/ha): {avg_train_mae:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo valid cross-validation folds were completed. Check your data and parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "748e1384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting yield prediction for all available polygons...\n",
      "\n",
      "--- Predicting for 'Munda1' ---\n",
      "  Average predicted yield per hectare: 0.900 tons/ha\n",
      "  Total predicted maize yield: 0.092 tons\n",
      "\n",
      "--- Predicting for 'Munda2' ---\n",
      "  Average predicted yield per hectare: 1.300 tons/ha\n",
      "  Total predicted maize yield: 0.441 tons\n",
      "\n",
      "--- Predicting for 'Munda3' ---\n",
      "  Average predicted yield per hectare: 1.400 tons/ha\n",
      "  Total predicted maize yield: 0.431 tons\n",
      "\n",
      "--- Predicting for 'Munda4' ---\n",
      "  Average predicted yield per hectare: 0.700 tons/ha\n",
      "  Total predicted maize yield: 0.203 tons\n",
      "\n",
      "--- Predicting for 'Munda5' ---\n",
      "  Average predicted yield per hectare: 1.100 tons/ha\n",
      "  Total predicted maize yield: 0.204 tons\n",
      "\n",
      "--- Predicting for 'Munda6' ---\n",
      "  Average predicted yield per hectare: 1.843 tons/ha\n",
      "  Total predicted maize yield: 0.115 tons\n",
      "\n",
      "--- Predicting for 'Munda7' ---\n",
      "  Average predicted yield per hectare: 77945.680 tons/ha\n",
      "  Total predicted maize yield: 69137.818 tons\n",
      "\n",
      "✅ Prediction process completed for all available polygons.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define features that your 'model' was trained on.\n",
    "# This list must match the 'features' list used in your model training (e.g., in the LOOCV cell).\n",
    "features = [\n",
    "    'mean_ExG',\n",
    "    'mean_GLI',\n",
    "    'mean_VARI',\n",
    "    'mean_TGI',\n",
    "    'mean_CIVE',\n",
    "    'mean_Red',\n",
    "    'mean_Green',\n",
    "    'mean_Blue'\n",
    "]\n",
    "\n",
    "# Get a list of all unique polygons present in df_indices.\n",
    "# df_indices should already contain all the drone features and the 'area_ha' column\n",
    "# merged from 'polygon_areas.csv'.\n",
    "unique_polygons_for_prediction = df_indices['polygon'].unique()\n",
    "\n",
    "print(\"Starting yield prediction for all available polygons...\")\n",
    "\n",
    "# Loop through each unique polygon to predict its yield.\n",
    "for polygon_name in unique_polygons_for_prediction:\n",
    "    print(f\"\\n--- Predicting for '{polygon_name}' ---\")\n",
    "\n",
    "    # Filter df_indices to get data only for the current polygon.\n",
    "    df_current_polygon = df_indices[df_indices['polygon'] == polygon_name].copy()\n",
    "\n",
    "    # Ensure the current polygon has data and all necessary features.\n",
    "    if df_current_polygon.empty:\n",
    "        print(f\"Warning: No data found for polygon '{polygon_name}'. Skipping prediction.\")\n",
    "        continue\n",
    "\n",
    "    # Check if all required features are present in the current polygon's data.\n",
    "    missing_features = [f for f in features if f not in df_current_polygon.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Error: Missing features for polygon '{polygon_name}': {missing_features}. Skipping prediction.\")\n",
    "        continue\n",
    "\n",
    "    # Predict yield per hectare for each image within the current polygon.\n",
    "    # The 'model' object must have been trained in a previous cell.\n",
    "    # Ensure that the 'model' object is available in your environment.\n",
    "    try:\n",
    "        df_current_polygon['predicted_yield_per_ha'] = model.predict(df_current_polygon[features])\n",
    "    except NameError:\n",
    "        print(\"Error: 'model' is not defined. Please ensure the model training cell was run successfully.\")\n",
    "        break # Exit the loop if model is not trained\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting for '{polygon_name}': {e}. Skipping prediction for this polygon.\")\n",
    "        continue\n",
    "\n",
    "    # Calculate the average predicted yield per hectare across all images for this polygon.\n",
    "    avg_predicted_yield_per_ha = np.nanmean(df_current_polygon['predicted_yield_per_ha'])\n",
    "\n",
    "    # Get the polygon area for the current polygon.\n",
    "    # This assumes 'area_ha' column exists and is not NaN for this polygon.\n",
    "    # We take the mean in case there are multiple entries for the same polygon, though ideally 'area_ha' should be constant.\n",
    "    if 'area_ha' in df_current_polygon.columns and not df_current_polygon['area_ha'].empty and not pd.isna(df_current_polygon['area_ha'].iloc[0]):\n",
    "        polygon_area = df_current_polygon['area_ha'].iloc[0] # Assuming area is constant per polygon\n",
    "\n",
    "        # Calculate the total predicted yield in tons for the entire polygon.\n",
    "        total_predicted_yield = avg_predicted_yield_per_ha * polygon_area\n",
    "\n",
    "        # Print the results for the current polygon.\n",
    "        print(f\"  Average predicted yield per hectare: {avg_predicted_yield_per_ha:.3f} tons/ha\")\n",
    "        print(f\"  Total predicted maize yield: {total_predicted_yield:.3f} tons\")\n",
    "    else:\n",
    "        # Handle cases where 'area_ha' is missing or invalid for the current polygon.\n",
    "        print(f\"  ⚠️ Warning: '{polygon_name}' 'area_ha' is missing or invalid. Cannot calculate total predicted yield.\")\n",
    "        print(f\"  Average predicted yield per hectare: {avg_predicted_yield_per_ha:.3f} tons/ha (Total yield calculation requires area)\")\n",
    "\n",
    "print(\"\\n✅ Prediction process completed for all available polygons.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a609c2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting yield prediction for 'Munda6' only...\n",
      "  Average predicted yield per hectare: 1.843 tons/ha\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Ensure pandas is imported if not already in the environment\n",
    "import numpy as np # Ensure numpy is imported for np.nanmean\n",
    "\n",
    "# Define features that your 'model' was trained on.\n",
    "# This list must match the 'features' list used in your model training (e.g., in the LOOCV cell).\n",
    "features = [\n",
    "    'mean_ExG',\n",
    "    'mean_GLI',\n",
    "    'mean_VARI',\n",
    "    'mean_TGI',\n",
    "    'mean_CIVE',\n",
    "    'mean_Red',\n",
    "    'mean_Green',\n",
    "    'mean_Blue',\n",
    "]\n",
    "\n",
    "# Define the specific polygon for which we want to predict the yield.\n",
    "polygon_to_predict = 'Munda6'\n",
    "\n",
    "print(f\"Starting yield prediction for '{polygon_to_predict}' only...\")\n",
    "\n",
    "# Filter df_indices to get data only for the specified polygon.\n",
    "# df_indices should already contain all the drone features and the 'area_ha' column\n",
    "# merged from 'polygon_areas.csv'.\n",
    "df_specific_polygon = df_indices[df_indices['polygon'] == polygon_to_predict].copy()\n",
    "\n",
    "# Ensure the specific polygon has data and all necessary features.\n",
    "if df_specific_polygon.empty:\n",
    "    print(f\"Error: No data found for polygon '{polygon_to_predict}'. Cannot proceed with prediction.\")\n",
    "else:\n",
    "    # Check if all required features are present in the polygon's data.\n",
    "    missing_features = [f for f in features if f not in df_specific_polygon.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Error: Missing features for polygon '{polygon_to_predict}': {missing_features}. Cannot proceed with prediction.\")\n",
    "    else:\n",
    "        # Predict yield per hectare for each image within this polygon.\n",
    "        # The 'model' object must have been trained in a previous cell (e.g., the LOOCV cell).\n",
    "        # Ensure that the 'model' object is available in your environment.\n",
    "        try:\n",
    "            df_specific_polygon['predicted_yield_per_ha'] = model.predict(df_specific_polygon[features])\n",
    "        except NameError:\n",
    "            print(\"Error: 'model' is not defined. Please ensure the model training cell was run successfully before running this prediction.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during prediction for '{polygon_to_predict}': {e}.\")\n",
    "        else:\n",
    "            # Calculate the average predicted yield per hectare across all images for this polygon.\n",
    "            avg_predicted_yield_per_ha = np.nanmean(df_specific_polygon['predicted_yield_per_ha'])\n",
    "\n",
    "            # Get the polygon area for the current polygon.\n",
    "            # This assumes 'area_ha' column exists and is not NaN for this polygon.\n",
    "            # We take the first value as area should be constant for a given polygon.\n",
    "            if 'area_ha' in df_specific_polygon.columns and not df_specific_polygon['area_ha'].empty and not pd.isna(df_specific_polygon['area_ha'].iloc[0]):\n",
    "                polygon_area = df_specific_polygon['area_ha'].iloc[0]\n",
    "\n",
    "                # Calculate the total predicted yield in tons for the entire polygon.\n",
    "                total_predicted_yield = avg_predicted_yield_per_ha * polygon_area\n",
    "\n",
    "                # Print the results for the specific polygon.\n",
    "                print(f\"  Average predicted yield per hectare: {avg_predicted_yield_per_ha:.3f} tons/ha\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
